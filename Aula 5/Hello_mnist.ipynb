{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LucaswasTaken/NES-DataScience/blob/main/Aula%205/Hello_mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5ZjjwspTvtc"
      },
      "source": [
        "## Objetivos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ocPaqDXTvtc"
      },
      "source": [
        "* Entender como o aprendizado profundo pode resolver problemas que os métodos tradicionais de programação não podem\n",
        "* Saiba mais sobre o [conjunto de dados de dígitos manuscritos do MNIST](http://yann.lecun.com/exdb/mnist/)\n",
        "* Use o [Keras API](https://keras.io/) para carregar o conjunto de dados MNIST e prepará-lo para o treinamento\n",
        "* Criar uma rede neural simples para realizar a classificação da imagem\n",
        "* Treinar a rede neural utilizando o conjunto de dados MNIST preparados\n",
        "* Observar o desempenho da rede neural treinada"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1N4vTXB_Tvtc"
      },
      "source": [
        "## O problema: Classificação da imagem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kn7ONUMoTvtc"
      },
      "source": [
        "Na programação tradicional, o programador é capaz de articular regras e condições em seu código que seu programa pode então usar para agir da maneira correta. Esta abordagem continua a funcionar excepcionalmente bem para uma enorme variedade de problemas.\n",
        "\n",
        "A classificação de imagens, que pede a um programa que classifique corretamente uma imagem que nunca viu antes em sua classe correta, é quase impossível de resolver com as técnicas tradicionais de programação. Como um programador poderia definir as regras e condições para classificar corretamente uma enorme variedade de imagens, especialmente levando em conta imagens que ele nunca viu?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7OzhILJUTvtc"
      },
      "source": [
        "## A Solução: Deep Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OoWXwHInTvtc"
      },
      "source": [
        "O aprendizado profundo (Deep Learning) se sobressai no reconhecimento de padrões por tentativa e erro. Ao treinar uma rede neural profunda com dados suficientes e fornecer à rede um feedback sobre seu desempenho através de treinamento, a rede pode identificar, embora uma enorme quantidade de iteração, seu próprio conjunto de condições pelas quais pode agir da maneira correta."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gECatU64Tvtc"
      },
      "source": [
        "## O MNIST Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p8LTC55ETvtd"
      },
      "source": [
        "Na história do aprendizado profundo, a classificação precisa da imagem do [conjunto de dados MNIST] (http://yann.lecun.com/exdb/mnist/), uma coleção de 70.000 imagens em escala de cinza com dígitos escritos à mão de 0 a 9, foi um grande desenvolvimento. Embora hoje o problema seja considerado trivial, fazer a classificação de imagens com o MNIST tornou-se uma espécie de \"Olá Mundo\" para um aprendizado profundo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yP1L6XCyTvtd"
      },
      "source": [
        "## Dados e labels/etiquetas de treinamento e validação"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzVX-ZIzTvtd"
      },
      "source": [
        "1. `x_train`: Imagens utilizadas para o treinamento da rede neural\n",
        "2. `y_train`: labels/etiquetas corretas para as imagens do `x_train`, utilizadas para avaliar as previsões do modelo durante o treinamento.\n",
        "3. `x_valid`: Imagens reservadas para validar o desempenho do modelo após ter sido treinado\n",
        "4. `y_valid`: labels/etiquetas corretas para as imagens `x_valid`, utilizadas para avaliar as previsões do modelo após ter sido treinado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tj-AREJuTvtd"
      },
      "source": [
        "## Carregando os dados na memória (com Keras)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kD_ilEynTvtd"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.datasets import mnist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbDJrbj6Tvtd",
        "outputId": "979c4ab3-e045-4e5b-91b0-c5a719f2d542"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "# os dados, divididos entre o treino e os conjuntos de validação\n",
        "(x_train, y_train), (x_valid, y_valid) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Edidmb2RTvtd"
      },
      "source": [
        "## Explorando os dados MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OavHjg_TTvtd"
      },
      "source": [
        "Declaramos acima que o conjunto de dados MNIST continha 70.000 imagens em escala de cinza de dígitos escritos à mão. Ao executar as seguintes células, podemos ver que a Keras partiu 60.000 destas imagens para treinamento, e 10.000 para validação (após treinamento), e também, que cada imagem em si é uma matriz 2D com as dimensões 28x28:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yn3uCmLdTvtd",
        "outputId": "5122d36d-a09e-49c3-8a5c-e613743629cf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "x_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FifgMuI9Tvtd",
        "outputId": "4959d8b8-efcc-462d-92cd-450f78ddeea3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "x_valid.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "De8CC1ILTvtd"
      },
      "source": [
        "Além disso, podemos ver que estas imagens 28x28 são representadas como uma coleção de valores inteiros não assinados de 8 bits entre 0 e 255, os valores correspondentes a um valor de escala de cinza de pixel onde `0` é preto, `255` é branco, e todos os outros valores estão no meio:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9OmzL92Tvtd",
        "outputId": "300af5f7-69ab-413c-d98f-100845a294e5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('uint8')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "x_train.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPPlV5ecTvtd",
        "outputId": "0f4345aa-510f-46d5-a16b-b3937bf1bbca"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.uint8(0)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "x_train.min()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hrmCev7aTvtd",
        "outputId": "069edcf1-9544-4f9d-a5c7-55571cf03664"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.uint8(255)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "x_train.max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "id": "MQj5vZdKTvtd",
        "outputId": "c9fde659-a3f3-4ac0-95c5-8248f40d0f31"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
              "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
              "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
              "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
              "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
              "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
              "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
              "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
              "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
              "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
              "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
              "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
              "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
              "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
              "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]], dtype=uint8)"
            ],
            "text/html": [
              "<style>\n",
              "      .ndarray_repr .ndarray_raw_data {\n",
              "        display: none;\n",
              "      }\n",
              "      .ndarray_repr.show_array .ndarray_raw_data {\n",
              "        display: block;\n",
              "      }\n",
              "      .ndarray_repr.show_array .ndarray_image_preview {\n",
              "        display: none;\n",
              "      }\n",
              "      </style>\n",
              "      <div id=\"id-7db2d209-438f-43a7-acfc-23fdd8c613bf\" class=\"ndarray_repr\"><pre>ndarray (28, 28) <button style=\"padding: 0 2px;\">show data</button></pre><img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABAElEQVR4nGNgGMyAWUhIqK5jvdSy/9/rGRgYGFhgEnJsVjYCwQwMDAxPJgV+vniQgYGBgREqZ7iXH8r6l/SV4dn7m8gmCt3++/fv37/Htn3/iMW+gDnZf/+e5WbQnoXNNXyMs/5GoQoxwVmf/n9kSGFiwAW49/11wynJoPzx4YIcRlyygR/+/i2XxCWru+vv32nSuGQFYv/83Y3b4p9/fzpAmSyoMnohpiwM1w5h06Q+5enfv39/bcMiJVF09+/fv39P+mFKiTtd/fv3799jgZiBJLT69t+/f/8eDuDEkDJf8+jv379/v7Ryo4qzMDAwMAQGMjBc3/y35wM2V1IfAABFF16Aa0wAOwAAAABJRU5ErkJggg==\" class=\"ndarray_image_preview\" /><pre class=\"ndarray_raw_data\">array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
              "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
              "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
              "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
              "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
              "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
              "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
              "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
              "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
              "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
              "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
              "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
              "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
              "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
              "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]], dtype=uint8)</pre></div><script>\n",
              "      (() => {\n",
              "      const titles = ['show data', 'hide data'];\n",
              "      let index = 0\n",
              "      document.querySelector('#id-7db2d209-438f-43a7-acfc-23fdd8c613bf button').onclick = (e) => {\n",
              "        document.querySelector('#id-7db2d209-438f-43a7-acfc-23fdd8c613bf').classList.toggle('show_array');\n",
              "        index = (++index) % 2;\n",
              "        document.querySelector('#id-7db2d209-438f-43a7-acfc-23fdd8c613bf button').textContent = titles[index];\n",
              "        e.preventDefault();\n",
              "        e.stopPropagation();\n",
              "      }\n",
              "      })();\n",
              "    </script>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "x_train[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7NFs1NTTvtd"
      },
      "source": [
        "Usando [Matplotlib](https://matplotlib.org/), podemos renderizar uma dessas imagens em escala de cinza em nosso conjunto de dados:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "SCIcYI3CTvtd",
        "outputId": "58239029-6954-47e1-ab56-ca4e77276ab2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7a3497449a50>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAG3tJREFUeJzt3X9sVfX9x/HX5UeviO3tSm1vKz8soLCJYMag61TEUSndRuTHFnUuwc1ocK0RmLjUTNFtrg6nM2xM+WOBsQkoyYBBFjYttmSzYEAYMW4NJd1aRlsmW+8thRZsP98/iPfLlRY8l3v7vr08H8knofeed+/H47VPb3s59TnnnAAA6GeDrDcAALgyESAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGBiiPUGPqmnp0fHjh1Tenq6fD6f9XYAAB4559Te3q78/HwNGtT365ykC9CxY8c0atQo620AAC5TU1OTRo4c2ef9SfctuPT0dOstAADi4FJfzxMWoNWrV+v666/XVVddpcLCQr377rufao5vuwFAarjU1/OEBOj111/XsmXLtGLFCr333nuaMmWKSkpKdPz48UQ8HABgIHIJMH36dFdWVhb5uLu72+Xn57vKyspLzoZCISeJxWKxWAN8hUKhi369j/sroDNnzmj//v0qLi6O3DZo0CAVFxertrb2guO7uroUDoejFgAg9cU9QB9++KG6u7uVm5sbdXtubq5aWlouOL6yslKBQCCyeAccAFwZzN8FV1FRoVAoFFlNTU3WWwIA9IO4/z2g7OxsDR48WK2trVG3t7a2KhgMXnC83++X3++P9zYAAEku7q+A0tLSNHXqVFVVVUVu6+npUVVVlYqKiuL9cACAASohV0JYtmyZFi1apC984QuaPn26Xn75ZXV0dOjb3/52Ih4OADAAJSRA99xzj/7zn//o6aefVktLi2655Rbt3LnzgjcmAACuXD7nnLPexPnC4bACgYD1NgAAlykUCikjI6PP+83fBQcAuDIRIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJoZYbwBIJoMHD/Y8EwgEErCT+CgvL49p7uqrr/Y8M2HCBM8zZWVlnmd+9rOfeZ657777PM9IUmdnp+eZ559/3vPMs88+63kmFfAKCABgggABAEzEPUDPPPOMfD5f1Jo4cWK8HwYAMMAl5GdAN910k956663/f5Ah/KgJABAtIWUYMmSIgsFgIj41ACBFJORnQIcPH1Z+fr7Gjh2r+++/X42NjX0e29XVpXA4HLUAAKkv7gEqLCzUunXrtHPnTr3yyitqaGjQ7bffrvb29l6Pr6ysVCAQiKxRo0bFe0sAgCQU9wCVlpbqG9/4hiZPnqySkhL98Y9/VFtbm954441ej6+oqFAoFIqspqameG8JAJCEEv7ugMzMTN14442qr6/v9X6/3y+/35/obQAAkkzC/x7QyZMndeTIEeXl5SX6oQAAA0jcA/T444+rpqZG//znP/XOO+9o/vz5Gjx4cMyXwgAApKa4fwvu6NGjuu+++3TixAlde+21uu2227Rnzx5de+218X4oAMAAFvcAbdq0Kd6fEklq9OjRnmfS0tI8z3zpS1/yPHPbbbd5npHO/czSq4ULF8b0WKnm6NGjnmdWrVrleWb+/PmeZ/p6F+6l/O1vf/M8U1NTE9NjXYm4FhwAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYMLnnHPWmzhfOBxWIBCw3sYV5ZZbbolpbteuXZ5n+Hc7MPT09Hie+c53vuN55uTJk55nYtHc3BzT3P/+9z/PM3V1dTE9VioKhULKyMjo835eAQEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMDEEOsNwF5jY2NMcydOnPA8w9Wwz9m7d6/nmba2Ns8zd955p+cZSTpz5oznmd/+9rcxPRauXLwCAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMcDFS6L///W9Mc8uXL/c887Wvfc3zzIEDBzzPrFq1yvNMrA4ePOh55q677vI809HR4Xnmpptu8jwjSY899lhMc4AXvAICAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEz4nHPOehPnC4fDCgQC1ttAgmRkZHieaW9v9zyzZs0azzOS9OCDD3qe+da3vuV5ZuPGjZ5ngIEmFApd9L95XgEBAEwQIACACc8B2r17t+bOnav8/Hz5fD5t3bo16n7nnJ5++mnl5eVp2LBhKi4u1uHDh+O1XwBAivAcoI6ODk2ZMkWrV6/u9f6VK1dq1apVevXVV7V3714NHz5cJSUl6uzsvOzNAgBSh+ffiFpaWqrS0tJe73PO6eWXX9YPfvAD3X333ZKk9evXKzc3V1u3btW99957ebsFAKSMuP4MqKGhQS0tLSouLo7cFggEVFhYqNra2l5nurq6FA6HoxYAIPXFNUAtLS2SpNzc3Kjbc3NzI/d9UmVlpQKBQGSNGjUqnlsCACQp83fBVVRUKBQKRVZTU5P1lgAA/SCuAQoGg5Kk1tbWqNtbW1sj932S3+9XRkZG1AIApL64BqigoEDBYFBVVVWR28LhsPbu3auioqJ4PhQAYIDz/C64kydPqr6+PvJxQ0ODDh48qKysLI0ePVpLlizRj3/8Y91www0qKCjQU089pfz8fM2bNy+e+wYADHCeA7Rv3z7deeedkY+XLVsmSVq0aJHWrVunJ554Qh0dHXr44YfV1tam2267TTt37tRVV10Vv10DAAY8LkaKlPTCCy/ENPfx/1B5UVNT43nm/L+q8Gn19PR4ngEscTFSAEBSIkAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAmuho2UNHz48Jjmtm/f7nnmjjvu8DxTWlrqeebPf/6z5xnAElfDBgAkJQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABBcjBc4zbtw4zzPvvfee55m2tjbPM2+//bbnmX379nmekaTVq1d7nkmyLyVIAlyMFACQlAgQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAE1yMFLhM8+fP9zyzdu1azzPp6emeZ2L15JNPep5Zv36955nm5mbPMxg4uBgpACApESAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmuBgpYGDSpEmeZ1566SXPM7NmzfI8E6s1a9Z4nnnuuec8z/z73//2PAMbXIwUAJCUCBAAwITnAO3evVtz585Vfn6+fD6ftm7dGnX/Aw88IJ/PF7XmzJkTr/0CAFKE5wB1dHRoypQpWr16dZ/HzJkzR83NzZG1cePGy9okACD1DPE6UFpaqtLS0ose4/f7FQwGY94UACD1JeRnQNXV1crJydGECRP0yCOP6MSJE30e29XVpXA4HLUAAKkv7gGaM2eO1q9fr6qqKv30pz9VTU2NSktL1d3d3evxlZWVCgQCkTVq1Kh4bwkAkIQ8fwvuUu69997In2+++WZNnjxZ48aNU3V1da9/J6GiokLLli2LfBwOh4kQAFwBEv427LFjxyo7O1v19fW93u/3+5WRkRG1AACpL+EBOnr0qE6cOKG8vLxEPxQAYADx/C24kydPRr2aaWho0MGDB5WVlaWsrCw9++yzWrhwoYLBoI4cOaInnnhC48ePV0lJSVw3DgAY2DwHaN++fbrzzjsjH3/885tFixbplVde0aFDh/Sb3/xGbW1tys/P1+zZs/WjH/1Ifr8/frsGAAx4XIwUGCAyMzM9z8ydOzemx1q7dq3nGZ/P53lm165dnmfuuusuzzOwwcVIAQBJiQABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACa4GjaAC3R1dXmeGTLE82930UcffeR5JpbfLVZdXe15BpePq2EDAJISAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGDC+9UDAVy2yZMne575+te/7nlm2rRpnmek2C4sGosPPvjA88zu3bsTsBNY4BUQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCi5EC55kwYYLnmfLycs8zCxYs8DwTDAY9z/Sn7u5uzzPNzc2eZ3p6ejzPIDnxCggAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMMHFSJH0YrkI53333RfTY8VyYdHrr78+psdKZvv27fM889xzz3me+cMf/uB5BqmDV0AAABMECABgwlOAKisrNW3aNKWnpysnJ0fz5s1TXV1d1DGdnZ0qKyvTiBEjdM0112jhwoVqbW2N66YBAAOfpwDV1NSorKxMe/bs0ZtvvqmzZ89q9uzZ6ujoiByzdOlSbd++XZs3b1ZNTY2OHTsW0y/fAgCkNk9vQti5c2fUx+vWrVNOTo7279+vGTNmKBQK6de//rU2bNigL3/5y5KktWvX6rOf/az27NmjL37xi/HbOQBgQLusnwGFQiFJUlZWliRp//79Onv2rIqLiyPHTJw4UaNHj1ZtbW2vn6Orq0vhcDhqAQBSX8wB6unp0ZIlS3Trrbdq0qRJkqSWlhalpaUpMzMz6tjc3Fy1tLT0+nkqKysVCAQia9SoUbFuCQAwgMQcoLKyMr3//vvatGnTZW2goqJCoVAospqami7r8wEABoaY/iJqeXm5duzYod27d2vkyJGR24PBoM6cOaO2traoV0Gtra19/mVCv98vv98fyzYAAAOYp1dAzjmVl5dry5Yt2rVrlwoKCqLunzp1qoYOHaqqqqrIbXV1dWpsbFRRUVF8dgwASAmeXgGVlZVpw4YN2rZtm9LT0yM/1wkEAho2bJgCgYAefPBBLVu2TFlZWcrIyNCjjz6qoqIi3gEHAIjiKUCvvPKKJGnmzJlRt69du1YPPPCAJOnnP/+5Bg0apIULF6qrq0slJSX61a9+FZfNAgBSh88556w3cb5wOKxAIGC9DXwKubm5nmc+97nPeZ755S9/6Xlm4sSJnmeS3d69ez3PvPDCCzE91rZt2zzP9PT0xPRYSF2hUEgZGRl93s+14AAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGAipt+IiuSVlZXleWbNmjUxPdYtt9zieWbs2LExPVYye+eddzzPvPjii55n/vSnP3meOX36tOcZoL/wCggAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMMHFSPtJYWGh55nly5d7npk+fbrnmeuuu87zTLI7depUTHOrVq3yPPOTn/zE80xHR4fnGSDV8AoIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADDBxUj7yfz58/tlpj998MEHnmd27Njheeajjz7yPPPiiy96npGktra2mOYAeMcrIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADAhM8556w3cb5wOKxAIGC9DQDAZQqFQsrIyOjzfl4BAQBMECAAgAlPAaqsrNS0adOUnp6unJwczZs3T3V1dVHHzJw5Uz6fL2otXrw4rpsGAAx8ngJUU1OjsrIy7dmzR2+++abOnj2r2bNnq6OjI+q4hx56SM3NzZG1cuXKuG4aADDwefqNqDt37oz6eN26dcrJydH+/fs1Y8aMyO1XX321gsFgfHYIAEhJl/UzoFAoJEnKysqKuv21115Tdna2Jk2apIqKCp06darPz9HV1aVwOBy1AABXABej7u5u99WvftXdeuutUbevWbPG7dy50x06dMj97ne/c9ddd52bP39+n59nxYoVThKLxWKxUmyFQqGLdiTmAC1evNiNGTPGNTU1XfS4qqoqJ8nV19f3en9nZ6cLhUKR1dTUZH7SWCwWi3X561IB8vQzoI+Vl5drx44d2r17t0aOHHnRYwsLCyVJ9fX1Gjdu3AX3+/1++f3+WLYBABjAPAXIOadHH31UW7ZsUXV1tQoKCi45c/DgQUlSXl5eTBsEAKQmTwEqKyvThg0btG3bNqWnp6ulpUWSFAgENGzYMB05ckQbNmzQV77yFY0YMUKHDh3S0qVLNWPGDE2ePDkh/wAAgAHKy8991Mf3+dauXeucc66xsdHNmDHDZWVlOb/f78aPH++WL19+ye8Dni8UCpl/35LFYrFYl78u9bWfi5ECABKCi5ECAJISAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMBE0gXIOWe9BQBAHFzq63nSBai9vd16CwCAOLjU13OfS7KXHD09PTp27JjS09Pl8/mi7guHwxo1apSampqUkZFhtEN7nIdzOA/ncB7O4TyckwznwTmn9vZ25efna9Cgvl/nDOnHPX0qgwYN0siRIy96TEZGxhX9BPsY5+EczsM5nIdzOA/nWJ+HQCBwyWOS7ltwAIArAwECAJgYUAHy+/1asWKF/H6/9VZMcR7O4Tycw3k4h/NwzkA6D0n3JgQAwJVhQL0CAgCkDgIEADBBgAAAJggQAMDEgAnQ6tWrdf311+uqq65SYWGh3n33Xest9btnnnlGPp8vak2cONF6Wwm3e/duzZ07V/n5+fL5fNq6dWvU/c45Pf3008rLy9OwYcNUXFysw4cP22w2gS51Hh544IELnh9z5syx2WyCVFZWatq0aUpPT1dOTo7mzZunurq6qGM6OztVVlamESNG6JprrtHChQvV2tpqtOPE+DTnYebMmRc8HxYvXmy0494NiAC9/vrrWrZsmVasWKH33ntPU6ZMUUlJiY4fP269tX530003qbm5ObL+8pe/WG8p4To6OjRlyhStXr261/tXrlypVatW6dVXX9XevXs1fPhwlZSUqLOzs593mliXOg+SNGfOnKjnx8aNG/txh4lXU1OjsrIy7dmzR2+++abOnj2r2bNnq6OjI3LM0qVLtX37dm3evFk1NTU6duyYFixYYLjr+Ps050GSHnrooajnw8qVK4123Ac3AEyfPt2VlZVFPu7u7nb5+fmusrLScFf9b8WKFW7KlCnW2zAlyW3ZsiXycU9PjwsGg+6FF16I3NbW1ub8fr/buHGjwQ77xyfPg3POLVq0yN19990m+7Fy/PhxJ8nV1NQ45879ux86dKjbvHlz5Ji///3vTpKrra212mbCffI8OOfcHXfc4R577DG7TX0KSf8K6MyZM9q/f7+Ki4sjtw0aNEjFxcWqra013JmNw4cPKz8/X2PHjtX999+vxsZG6y2ZamhoUEtLS9TzIxAIqLCw8Ip8flRXVysnJ0cTJkzQI488ohMnTlhvKaFCoZAkKSsrS5K0f/9+nT17Nur5MHHiRI0ePTqlnw+fPA8fe+2115Sdna1JkyapoqJCp06dsthen5LuYqSf9OGHH6q7u1u5ublRt+fm5uof//iH0a5sFBYWat26dZowYYKam5v17LPP6vbbb9f777+v9PR06+2ZaGlpkaRenx8f33elmDNnjhYsWKCCggIdOXJETz75pEpLS1VbW6vBgwdbby/uenp6tGTJEt16662aNGmSpHPPh7S0NGVmZkYdm8rPh97OgyR985vf1JgxY5Sfn69Dhw7p+9//vurq6vT73//ecLfRkj5A+H+lpaWRP0+ePFmFhYUaM2aM3njjDT344IOGO0MyuPfeeyN/vvnmmzV58mSNGzdO1dXVmjVrluHOEqOsrEzvv//+FfFz0Ivp6zw8/PDDkT/ffPPNysvL06xZs3TkyBGNGzeuv7fZq6T/Flx2drYGDx58wbtYWltbFQwGjXaVHDIzM3XjjTeqvr7eeitmPn4O8Py40NixY5WdnZ2Sz4/y8nLt2LFDb7/9dtSvbwkGgzpz5oza2tqijk/V50Nf56E3hYWFkpRUz4ekD1BaWpqmTp2qqqqqyG09PT2qqqpSUVGR4c7snTx5UkeOHFFeXp71VswUFBQoGAxGPT/C4bD27t17xT8/jh49qhMnTqTU88M5p/Lycm3ZskW7du1SQUFB1P1Tp07V0KFDo54PdXV1amxsTKnnw6XOQ28OHjwoScn1fLB+F8SnsWnTJuf3+926devcBx984B5++GGXmZnpWlparLfWr773ve+56upq19DQ4P7617+64uJil52d7Y4fP269tYRqb293Bw4ccAcOHHCS3EsvveQOHDjg/vWvfznnnHv++eddZmam27Ztmzt06JC7++67XUFBgTt9+rTxzuPrYuehvb3dPf744662ttY1NDS4t956y33+8593N9xwg+vs7LTeetw88sgjLhAIuOrqatfc3BxZp06dihyzePFiN3r0aLdr1y63b98+V1RU5IqKigx3HX+XOg/19fXuhz/8odu3b59raGhw27Ztc2PHjnUzZsww3nm0AREg55z7xS9+4UaPHu3S0tLc9OnT3Z49e6y31O/uuecel5eX59LS0tx1113n7rnnHldfX2+9rYR7++23naQL1qJFi5xz596K/dRTT7nc3Fzn9/vdrFmzXF1dne2mE+Bi5+HUqVNu9uzZ7tprr3VDhw51Y8aMcQ899FDK/U9ab//8ktzatWsjx5w+fdp997vfdZ/5zGfc1Vdf7ebPn++am5vtNp0AlzoPjY2NbsaMGS4rK8v5/X43fvx4t3z5chcKhWw3/gn8OgYAgImk/xkQACA1ESAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAm/g8LqO+DMSLZbAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "image = x_train[0]\n",
        "plt.imshow(image, cmap='gray')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWelHk26Tvte"
      },
      "source": [
        "Desta forma, podemos ver agora que se trata de uma imagem de 28x28 pixels de um 5. Ou é um 3? A resposta está nos dados `y_train`, que contém etiquetas corretas para os dados. Vamos dar uma olhada:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZ8keHhmTvte",
        "outputId": "de901c72-face-4694-c6de-b00e1aeaa014"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.uint8(5)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "y_train[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZWzSnJ1Tvte"
      },
      "source": [
        "## Preparando os dados para o treinamento\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4s2sIspTvte"
      },
      "source": [
        "No aprendizado profundo, é comum que os dados precisem ser transformados para estarem no estado ideal para o treinamento. Para este problema particular de classificação da imagem, há 3 tarefas que devemos realizar com os dados em preparação para o treinamento:\n",
        "1. Flatten os dados da imagem, para simplificar a entrada da imagem no modelo\n",
        "2. Normalizar os dados da imagem, para facilitar o trabalho com os valores de entrada da imagem para o modelo\n",
        "3. Categorizar as etiquetas, para facilitar o trabalho com os valores das etiquetas para o modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQdx9t6nTvte"
      },
      "source": [
        "### Flattenando os dados de imagem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZgRPK24Tvte"
      },
      "source": [
        "Embora seja possível para um modelo de aprendizagem profunda aceitar uma imagem bidimensional (em nosso caso 28x28 pixels), vamos simplificar as coisas para começar e [reformular](https://www.tensorflow.org/api_docs/python/tf/reshape) cada imagem em um único conjunto de 784 pixels contínuos (nota: 28x28 = 784). Isto também é chamado de achatamento da imagem.\n",
        "\n",
        "Aqui realizamos isto utilizando o método de ajuda `reshape':"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OjqqbGSMTvte"
      },
      "outputs": [],
      "source": [
        "x_train = x_train.reshape(60000, 784)\n",
        "x_valid = x_valid.reshape(10000, 784)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqKKZ4czTvte"
      },
      "source": [
        "Podemos confirmar que os dados da imagem foram reformulados e são agora uma coleção de matrizes 1D contendo 784 valores de pixel cada uma:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMRtzep-Tvte",
        "outputId": "3cbe8ce6-868b-4163-d6d1-216c4db80263"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 784)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "x_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ja2WTQ1XTvte",
        "outputId": "1e9c9e12-9ebb-42d0-e066-ed63d83fa2f7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   3,  18,  18,  18,\n",
              "       126, 136, 175,  26, 166, 255, 247, 127,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170, 253,\n",
              "       253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253,\n",
              "       253, 253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  18, 219, 253,\n",
              "       253, 253, 253, 253, 198, 182, 247, 241,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "        80, 156, 107, 253, 253, 205,  11,   0,  43, 154,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,  14,   1, 154, 253,  90,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0, 139, 253, 190,   2,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190, 253,  70,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
              "       241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,  81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,  45, 186, 253, 253, 150,  27,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,  16,  93, 252, 253, 187,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 249,\n",
              "       253, 249,  64,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  46, 130,\n",
              "       183, 253, 253, 207,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39, 148,\n",
              "       229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114,\n",
              "       221, 253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  23,  66,\n",
              "       213, 253, 253, 253, 253, 198,  81,   2,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  18, 171,\n",
              "       219, 253, 253, 253, 253, 195,  80,   9,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  55, 172,\n",
              "       226, 253, 253, 253, 253, 244, 133,  11,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "       136, 253, 253, 253, 212, 135, 132,  16,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "x_train[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nqO8eGRTvte"
      },
      "source": [
        "### Normalizando os dados de imagem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_WzsLbUTvte"
      },
      "source": [
        "Modelos de aprendizagem profunda são melhores para lidar com números de ponto flutuante entre 0 e 1 (mais sobre este tópico mais adiante). A conversão de valores inteiros em valores de ponto flutuante entre 0 e 1 é chamada [normalização](https://developers.google.com/machine-learning/glossary#normalization), e uma abordagem simples que tomaremos aqui para normalizar os dados será dividir todos os valores de pixel (que se você se lembrar estão entre 0 e 255) por 255:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dyygcC8jTvte"
      },
      "outputs": [],
      "source": [
        "x_train = x_train / 255\n",
        "x_valid = x_valid / 255"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHf6xofzTvte"
      },
      "source": [
        "Agora podemos ver que todos os valores são valores de ponto flutuante entre `0,0` e `1,0`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IcCsHUWBTvte",
        "outputId": "7ced58c5-d557-4051-c6a2-e092e5377fa9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('float64')"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "x_train.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bfxbl7kGTvte",
        "outputId": "eaeb12c7-a32f-4ad0-f8c2-1ff606288ea6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(0.0)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "x_train.min()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vu8yUpyjTvte",
        "outputId": "fc56d3ee-d94f-476f-c7db-df0f00e05ec3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(1.0)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "x_train.max()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCAAhmZRTvte"
      },
      "source": [
        "### Categorical Encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bg4gfl2QTvte"
      },
      "source": [
        "Considere por um momento, se quiséssemos perguntar, o que é 7 - 2? Afirmar que a resposta foi 4 está mais perto do que afirmar que a resposta foi 9. No entanto, para este problema de classificação da imagem, não queremos que a rede neural aprenda este tipo de raciocínio: queremos apenas que ela selecione a categoria correta, e entenda que se tivermos uma imagem do número 5, essa suposição 4 é tão ruim quanto a suposição 9.\n",
        "\n",
        "No estado atual, os rótulos das imagens são inteiros entre 0 e 9. Como estes valores representam um intervalo numérico, o modelo pode tentar tirar algumas conclusões sobre seu desempenho com base em quão próximo da categoria numérica correta ele adivinha.\n",
        "\n",
        "Portanto, faremos algo aos nossos dados chamado codificação categórica. Este tipo de transformação modifica os dados para que cada valor seja uma coleção de todas as categorias possíveis, com a categoria real de que este valor particular é definido como verdadeiro.\n",
        "\n",
        "Como um exemplo simples, considere se tivéssemos 3 categorias: vermelho, azul e verde. Para uma determinada cor, 2 destas categorias seriam falsas, e a outra seria verdadeira:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rls8LRz6Tvte"
      },
      "source": [
        "|Actual Color| Is Red? | Is Blue? | Is Green?|\n",
        "|------------|---------|----------|----------|\n",
        "|Red|True|False|False|\n",
        "|Green|False|False|True|\n",
        "|Blue|False|True|False|\n",
        "|Green|False|False|True|"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1D9jhgX8Tvte"
      },
      "source": [
        "Em vez de usar \"Verdadeiro\" ou \"Falso\", poderíamos representar o mesmo usando o binário, seja 0 ou 1:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0heD4lUETvtf"
      },
      "source": [
        "|Actual Color| Is Red? | Is Blue? | Is Green?|\n",
        "|------------|---------|----------|----------|\n",
        "|Red|1|0|0|\n",
        "|Green|0|0|1|\n",
        "|Blue|0|1|0|\n",
        "|Green|0|0|1|"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66vM9rjbTvtf"
      },
      "source": [
        "Isto é o que é codificação categórica, transformando valores que devem ser entendidos como rótulos categóricos em uma representação que torna sua natureza categórica explícita ao modelo. Assim, se estivéssemos utilizando estes valores para treinamento, converteríamos..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kC2C2TuVTvtf"
      },
      "source": [
        "```python\n",
        "values = ['red, green, blue, green']\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "476zvQmDTvtf"
      },
      "source": [
        "... o que uma rede neural teria muita dificuldade de entender, ao invés disso:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMWzriLjTvtf"
      },
      "source": [
        "```python\n",
        "values = [\n",
        "    [1, 0, 0],\n",
        "    [0, 0, 1],\n",
        "    [0, 1, 0],\n",
        "    [0, 0, 1]\n",
        "]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5x3GOJLTvtf"
      },
      "source": [
        "### Codificação categórica dos labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbwgJ0kgTvtf"
      },
      "source": [
        "A Keras fornece uma utilidade para [codificar categoricamente valores](https://www.tensorflow.org/api_docs/python/tf/keras/utils/to_categorical), e aqui a usamos para realizar a codificação categórica tanto para as etiquetas de treinamento quanto para as etiquetas de validação:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lchuJmEsTvtf"
      },
      "outputs": [],
      "source": [
        "import tensorflow.keras as keras\n",
        "num_categories = 10\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train, num_categories)\n",
        "y_valid = keras.utils.to_categorical(y_valid, num_categories)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1o3-joHTvtf"
      },
      "source": [
        "Aqui estão os primeiros 10 valores das etiquetas de treinamento, que você pode ver que agora foram categoricamente codificados:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tAXts_wTvtf",
        "outputId": "154a141e-6526-44d5-9d88-cd7a374b40f2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "y_train[0:9]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7PWucKMTvtf"
      },
      "source": [
        "## Criando o modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FhuhPVaTvtf"
      },
      "source": [
        "Com os dados preparados para o treinamento, agora é hora de criar o modelo que iremos treinar com os dados. Este primeiro modelo básico será composto de várias *camadas* e será composto de 3 partes principais:\n",
        "\n",
        "1. Uma camada de entrada, que receberá os dados em algum formato esperado\n",
        "2. Várias [camadas ocultas](https://developers.google.com/machine-learning/glossary#hidden-layer), cada uma composta de muitos *neurônios*. Cada [neurônio](https://developers.google.com/machine-learning/glossary#neuron) terá a capacidade de afetar o palpite da rede com seus *pesos*, que são valores que serão atualizados ao longo de muitas iterações à medida que a rede recebe feedback sobre seu desempenho e aprende\n",
        "3. Uma camada de saída, que retratará o palpite da rede para uma determinada imagem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCq4wG9rTvtf"
      },
      "source": [
        "### Instanciando o modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_p8KMfmvTvtf"
      },
      "source": [
        "Para começar, usaremos a classe de modelo [Sequencial](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential) da Keras para instanciar uma instância de um modelo que terá uma série de camadas que os dados passarão em seqüência:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SvxVFWlqTvtf"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "model = Sequential()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZ9sTGTNTvtf"
      },
      "source": [
        "### Criação da camada de entrada"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KyAbw-fyTvtf"
      },
      "source": [
        "Em seguida, adicionaremos a camada de entrada. Esta camada estará *densamente conectada*, o que significa que cada neurônio nela, e seus pesos, afetarão cada neurônio da camada seguinte. Para fazer isto com Keras, usamos a classe de camada [Densa](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense) de Keras."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ql-1pa_bTvtf"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Dense"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8vuhMh4Tvtf"
      },
      "source": [
        "O argumento \"units\" especifica o número de neurônios na camada. Vamos utilizar o `512` que escolhemos a partir da experimentação. Escolher o número correto de neurônios é o que coloca a \"ciência\" na \"ciência dos dados\", pois é uma questão de capturar a complexidade estatística do conjunto de dados. Tente brincar com este valor mais tarde para ver como ele afeta o treinamento e para começar a desenvolver um sentido para o que este número significa.\n",
        "\n",
        "Aprenderemos mais sobre funções de ativação mais tarde, mas por enquanto, utilizaremos a função de ativação `relu`, que em resumo, ajudará nossa rede a aprender como fazer suposições mais sofisticadas sobre os dados do que se fosse necessário fazer suposições baseadas em alguma função estritamente linear.\n",
        "\n",
        "O valor `input_shape` especifica a forma dos dados recebidos que, em nossa situação, é uma matriz 1D de 784 valores:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88DR88aATvtf",
        "outputId": "ae58aa44-3b9d-4eb2-996f-981540c1764e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "model.add(Dense(units=512, activation='relu', input_shape=(784,)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOHxnyd9Tvtf"
      },
      "source": [
        "### Criando a camada oculta"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GzNhnFJeTvtf"
      },
      "source": [
        "Agora vamos acrescentar uma camada adicional densamente conectada. Mais uma vez, muito mais será dito sobre estes mais tarde, mas por enquanto sabemos que estas camadas dão à rede mais parâmetros para contribuir para seus palpites e, portanto, mais sutis oportunidades para um aprendizado preciso:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RIEupQyLTvtf"
      },
      "outputs": [],
      "source": [
        "model.add(Dense(units = 512, activation='relu'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NK0AyWLTvtf"
      },
      "source": [
        "### Criação da camada de saída"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "StuYWGNFTvtg"
      },
      "source": [
        "Finalmente, vamos adicionar uma camada de saída. Esta camada utiliza a função de ativação `softmax` que resultará em que cada um dos valores da camada será uma probabilidade entre 0 e 1 e resultará em todas as saídas da camada adicionando a 1. Neste caso, uma vez que a rede deve fazer um palpite sobre uma única imagem pertencente a 1 de 10 categorias possíveis, haverá 10 saídas. Cada saída dá o palpite do modelo (uma probabilidade) de que a imagem pertence a essa classe específica:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FxXg9mhRTvtg"
      },
      "outputs": [],
      "source": [
        "model.add(Dense(units = 10, activation='softmax'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4Rq2U_6Tvtg"
      },
      "source": [
        "### Resumindo o Modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HoOlYH2VTvtg"
      },
      "source": [
        "Keras fornece o método da instância modelo [resumo] (https://www.tensorflow.org/api_docs/python/tf/summary) que imprimirá um resumo legível de um modelo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "qtsC33eHTvtg",
        "outputId": "8454b6a8-e29c-4004-ae05-26a0baba8d11"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │         \u001b[38;5;34m401,920\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │         \u001b[38;5;34m262,656\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │           \u001b[38;5;34m5,130\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">401,920</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">5,130</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m669,706\u001b[0m (2.55 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">669,706</span> (2.55 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m669,706\u001b[0m (2.55 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">669,706</span> (2.55 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-x93r30ETvtg"
      },
      "source": [
        "Observe o número de parâmetros treináveis. Cada um deles pode ser ajustado durante o treinamento e irá contribuir para os palpites do modelo treinado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PMAwIcgTvtg"
      },
      "source": [
        "#### Compilação do modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8CjHjLe3Tvtg"
      },
      "source": [
        "Mais uma vez, mais detalhes devem ser seguidos, mas o passo final que precisamos dar antes de podermos realmente treinar nosso modelo com dados é [compilá-lo](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential#compile). Aqui especificamos uma [função de perda](https://developers.google.com/machine-learning/glossary#loss) que será usada para que o modelo entenda o seu desempenho durante o treinamento. Também especificamos que gostaríamos de rastrear a `accuracidade` enquanto o modelo treina:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3rvPuL39Tvtg"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKvL7YukTvtg"
      },
      "source": [
        "## Treinando o Modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSJSNmaNTvtg"
      },
      "source": [
        "Agora que preparamos dados de treinamento e validação e um modelo, é hora de treinar nosso modelo com nossos dados de treinamento, e verificá-lo com seus dados de validação.\n",
        "\n",
        "\"Treinar um modelo com dados\" também é freqüentemente chamado de \"ajustar um modelo aos dados\". Colocando desta última forma, ele destaca que a forma do modelo muda com o tempo para entender com mais precisão os dados que estão sendo fornecidos.\n",
        "\n",
        "Ao ajustar (treinar) um modelo com Keras, usamos o método [ajuste] (https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit) do modelo. Ele espera os seguintes argumentos:\n",
        "\n",
        "* Os dados de treinamento\n",
        "* As etiquetas para os dados de treinamento\n",
        "* O número de vezes que deve treinar em todo o conjunto de dados de treinamento (chamado *epoch*)\n",
        "* Os dados de validação ou teste, e suas etiquetas\n",
        "\n",
        "Execute a célula abaixo para treinar o modelo. Discutiremos sua saída após a conclusão do treinamento:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wx6fjY6ATvtg",
        "outputId": "7b0a1110-9c31-4ed5-dee7-e096b72e6cbb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 12ms/step - accuracy: 0.8989 - loss: 0.3193 - val_accuracy: 0.9675 - val_loss: 0.1114\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 10ms/step - accuracy: 0.9753 - loss: 0.0833 - val_accuracy: 0.9743 - val_loss: 0.0932\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.9832 - loss: 0.0595 - val_accuracy: 0.9787 - val_loss: 0.0863\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.9876 - loss: 0.0443 - val_accuracy: 0.9827 - val_loss: 0.0774\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step - accuracy: 0.9907 - loss: 0.0340 - val_accuracy: 0.9773 - val_loss: 0.1067\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    x_train, y_train, epochs=5, verbose=1, validation_data=(x_valid, y_valid)\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}