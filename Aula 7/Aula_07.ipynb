{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LucaswasTaken/NES-DataScience/blob/main/Aula%2007/Aula_07.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQ5zmYTUsE4Z"
      },
      "source": [
        "# Redes Neurais Convolucionais"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "bwnwUd0Bgtf3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKBqO4KhsE4b"
      },
      "source": [
        "## Objetivos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJzSyIrksE4c"
      },
      "source": [
        "* Dados de preparação especificamente para uma CNN\n",
        "* Criar um modelo CNN mais sofisticado, compreendendo uma maior variedade de camadas de modelos\n",
        "* Treinar um modelo CNN e observar seu desempenho"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxX5LikzsE4d"
      },
      "source": [
        "## Carregando e preparando os dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKMGeEYOsE4e"
      },
      "source": [
        "A célula abaixo contém as técnicas de pré-processamento de dados que aprendemos nos laboratórios anteriores. Revise e execute antes de seguir em frente:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "akGI1TQ6sE4f"
      },
      "outputs": [],
      "source": [
        "import tensorflow.keras as keras\n",
        "import pandas as pd\n",
        "\n",
        "# Load in our data from CSV files\n",
        "train_df = pd.read_csv(\"./sign_mnist_train.csv\")\n",
        "valid_df = pd.read_csv(\"./sign_mnist_valid.csv\")\n",
        "\n",
        "# Separate out our target values\n",
        "y_train = train_df['label']\n",
        "y_valid = valid_df['label']\n",
        "del train_df['label']\n",
        "del valid_df['label']\n",
        "\n",
        "# Separate out our image vectors\n",
        "x_train = train_df.values\n",
        "x_valid = valid_df.values\n",
        "\n",
        "# Turn our scalar targets into binary categories\n",
        "num_classes = 24\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_valid = keras.utils.to_categorical(y_valid, num_classes)\n",
        "\n",
        "# Normalize our image data\n",
        "x_train = x_train / 255\n",
        "x_valid = x_valid / 255"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qg2JSrEmsE4g"
      },
      "source": [
        "## Reformulação de imagens para uma CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xb64WgZzsE4h"
      },
      "source": [
        "No último exercício, as imagens individuais em nosso conjunto de dados estão no formato de longas listas de 784 pixels:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uTxpGVzCsE4h"
      },
      "outputs": [],
      "source": [
        "x_train.shape, x_valid.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khSuCA8rsE4h"
      },
      "source": [
        "Neste formato, não temos todas as informações sobre quais pixels estão próximos uns dos outros. Por causa disso, não podemos aplicar convoluções que detectem características. Vamos reformular nosso conjunto de dados para que eles estejam em um formato de 28x28 pixels. Isto permitirá que nossas convoluções associem grupos de pixels e detectem características importantes.\n",
        "\n",
        "Note que para a primeira camada convolucional de nosso modelo, precisamos ter não apenas a altura e largura da imagem, mas também o número de [canais de cor] (https://www.photoshopessentials.com/essentials/rgb/). Nossas imagens são em escala de cinza, portanto, teremos apenas 1 canal.\n",
        "\n",
        "Isso significa que precisamos converter a forma atual `(27455, 784)` para `(27455, 28, 28, 1)`. Como conveniência, podemos passar o método [reshape](https://numpy.org/doc/stable/reference/generated/numpy.reshape.html#numpy.reshape) um `-1` para qualquer dimensão que desejemos permanecer a mesma, portanto:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qe5Z-ESysE4i"
      },
      "outputs": [],
      "source": [
        "x_train = x_train.reshape(-1,28,28,1)\n",
        "x_valid = x_valid.reshape(-1,28,28,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h9uf34MksE4i"
      },
      "outputs": [],
      "source": [
        "x_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mfHXKqUssE4i"
      },
      "outputs": [],
      "source": [
        "x_valid.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ky0IGzlksE4j"
      },
      "outputs": [],
      "source": [
        "x_train.shape, x_valid.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spVe1Cx8sE4j"
      },
      "source": [
        "## Criando um Modelo Convolutivo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5mRhaneFsE4j"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import (\n",
        "    Dense,\n",
        "    Conv2D,\n",
        "    MaxPool2D,\n",
        "    Flatten,\n",
        "    Dropout,\n",
        "    BatchNormalization,\n",
        ")\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(75, (3, 3), strides=1, padding=\"same\", activation=\"relu\",\n",
        "                 input_shape=(28, 28, 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool2D((2, 2), strides=2, padding=\"same\"))\n",
        "model.add(Conv2D(50, (3, 3), strides=1, padding=\"same\", activation=\"relu\"))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool2D((2, 2), strides=2, padding=\"same\"))\n",
        "model.add(Conv2D(25, (3, 3), strides=1, padding=\"same\", activation=\"relu\"))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool2D((2, 2), strides=2, padding=\"same\"))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units=512, activation=\"relu\"))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(units=num_classes, activation=\"softmax\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5H8-e9pzsE4m"
      },
      "source": [
        "Aqui, resumimos o modelo que acabamos de criar. Observe como ele tem menos parâmetros treináveis do que o modelo do caderno anterior:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RIG6aeaesE4n"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xaPEM4yCsE4n"
      },
      "source": [
        "## Compiling the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOinHDkTsE4n"
      },
      "source": [
        "Vamos compilar o modelo exatamente como antes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "msz18LWcsE4n"
      },
      "outputs": [],
      "source": [
        "model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTVrjrxksE4n"
      },
      "source": [
        "## Treinando o Modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ow1LO_iEsE4o"
      },
      "source": [
        "Apesar da arquitetura de modelo muito diferente, o treinamento parece exatamente o mesmo. Execute a célula abaixo para treinar durante 20 épocas e vamos ver se a precisão melhora:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_13Jxra8sE4o"
      },
      "outputs": [],
      "source": [
        "model.fit(x_train, y_train, epochs=10, verbose=1, validation_data=(x_valid, y_valid))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yn3Du4BGsE4p"
      },
      "source": [
        "## Discussão dos resultados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmhNsxhosE4p"
      },
      "source": [
        "Parece que este modelo foi significativamente melhorado! A precisão do treinamento é muito alta, e a precisão da validação também melhorou. Este é um ótimo resultado, pois tudo o que tivemos que fazer foi trocar em um novo modelo.\n",
        "\n",
        "Você deve ter notado a precisão de validação pulando. Isto é uma indicação de que nosso modelo ainda não está se generalizando perfeitamente. Felizmente, há mais o que podemos fazer. Vamos falar sobre isso na próxima palestra."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}